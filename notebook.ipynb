{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9820730686187744}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"O diretor não aprovou a compra do carro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid model-index. Not loading eval results into CardData.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3feb5d35d4da4439ac49073ffd1f02ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb4534e95624fe18c3ece4a3ddbf3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rodri\\OneDrive\\Documentos\\GitHub\\goya\\.env\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rodri\\.cache\\huggingface\\hub\\models--stjiris--bert-large-portuguese-cased-legal-tsdae-gpl-nli-sts-MetaKD-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f82e43cb8d45bab411710f8bc1fea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300b934809e54010ac38309c29f4603e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0920d6664b1e4e07935a7d2d870a322b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c46ec63e244956a3b7a42914dc27ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/540 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae4827362454d8f8e05518a1d16e8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/678k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c83c0433214c8287ab51a74769cb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\rodri\\\\.cache\\\\huggingface\\\\hub\\\\models--stjiris--bert-large-portuguese-cased-legal-tsdae-gpl-nli-sts-MetaKD-v1\\\\snapshots\\\\d2d659ca0b9313de66035e14a181603344526d06'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(repo_id=\"stjiris/bert-large-portuguese-cased-legal-tsdae-gpl-nli-sts-MetaKD-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5719184  -0.5091155  -0.11547986 ...  1.0301195  -1.0442094\n",
      "  -0.7477195 ]\n",
      " [-1.1913166  -0.69083863  0.17472051 ...  1.0827106  -1.3476181\n",
      "  -0.32752746]]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"Isto é um exemplo\", \"Isto é um outro exemplo\"]\n",
    "\n",
    "model = SentenceTransformer('C:\\\\Users\\\\rodri\\\\.cache\\\\huggingface\\\\hub\\\\models--stjiris--bert-large-portuguese-cased-legal-tsdae-gpl-nli-sts-MetaKD-v1\\\\snapshots\\\\d2d659ca0b9313de66035e14a181603344526d06')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This framework generates embeddings for each input sentence\n",
      "Embedding: [ 0.32540998 -0.79077464  0.03738057 ... -0.08492672 -1.4870777\n",
      "  0.7626516 ]\n",
      "\n",
      "Sentence: Sentences are passed as a list of string.\n",
      "Embedding: [ 1.2157342  -0.6177284  -0.8864079  ... -0.7282589  -0.59214926\n",
      " -0.28579903]\n",
      "\n",
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Embedding: [-0.3508193  -0.0968128   0.13904814 ...  0.68020785 -0.22155814\n",
      "  0.46256638]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"C:\\\\Users\\\\rodri\\\\.cache\\\\huggingface\\\\hub\\\\models--stjiris--bert-large-portuguese-cased-legal-tsdae-gpl-nli-sts-MetaKD-v1\\\\snapshots\\\\d2d659ca0b9313de66035e14a181603344526d06\")\n",
    "\n",
    "# Our sentences to encode\n",
    "sentences = [\n",
    "    \"This framework generates embeddings for each input sentence\",\n",
    "    \"Sentences are passed as a list of string.\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\"\n",
    "]\n",
    "\n",
    "# Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.8119\n",
      "A man is eating a piece of bread. \t A man is riding a white horse on an enclosed ground. \t 0.6419\n",
      "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.6213\n",
      "A man is eating a piece of bread. \t A man is riding a horse. \t 0.5563\n",
      "The girl is carrying a baby. \t Two men pushed carts through the woods. \t 0.4301\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"C:\\\\Users\\\\rodri\\\\.cache\\\\huggingface\\\\hub\\\\models--stjiris--bert-large-portuguese-cased-legal-tsdae-gpl-nli-sts-MetaKD-v1\\\\snapshots\\\\d2d659ca0b9313de66035e14a181603344526d06\")\n",
    "\n",
    "sentences = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"Someone in a gorilla costume is playing a set of drums.\",\n",
    "]\n",
    "\n",
    "# Encode all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "# Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim) - 1):\n",
    "    for j in range(i + 1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "# Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
